{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfb1150-8fde-4930-88a9-740e78ace357",
   "metadata": {},
   "source": [
    "INTEGRANTES: BRUNO FIGUEROA\n",
    "\n",
    "En esta tarea, deberá comparar distintos algoritmos de aprendizaje supervisado y no supervisado sobre un mismo conjunto de datos de su elección.\n",
    "\n",
    "Su dataset deberá tener al menos 10.000 filas y 7 columnas utilizables.\n",
    "\n",
    "Además, seleccione una de las columnas como su etiqueta Y, la cual debe ser discreta y con más de 2 clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72078a49-075e-41de-9545-dbc6a3fb3b39",
   "metadata": {},
   "source": [
    "PUNTO 1:\n",
    "\n",
    "Deberá ejecutar tres algoritmos de clustering: K-Means, K-Means++ y MeanShift, utilizando al menos cuatro configuraciones distintas para cada técnica (deberá justificar la elección de parámetros).\n",
    "\n",
    "Para el entrenamiento, use únicamente el 80% de los datos, omitiendo la etiqueta Y. \n",
    "\n",
    "A continuación, evalúe las doce configuraciones obtenidas mediante una métrica de su elección (por ejemplo, Silhouette Score) y seleccione las tres de mejor desempeño. \n",
    "\n",
    "Luego, aplique cada una de estas configuraciones al 20% restante de los datos, asignando a cada muestra el cluster correspondiente (obtenidos desde el entrenamiento). \n",
    "\n",
    "Finalmente, compare la etiqueta Y real de cada muestra con la etiqueta dominante dentro del cluster al que pertenece y analice si este procedimiento resulta razonable para asignar etiquetas faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc439af7-373b-4ae0-ad94-ccfb4c4159e0",
   "metadata": {},
   "source": [
    "Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6c3d5c-5503-428d-8d13-05c7a814cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3ae5a-9b81-4725-a2ec-3ebea08e9c69",
   "metadata": {},
   "source": [
    "Importar librerias para punto 1 y 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b5b82d-e13e-461c-82c0-d556178f04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d073a99-771a-420f-bebc-12afb71ddf68",
   "metadata": {},
   "source": [
    "Cargar dataset como DataFrame y sacar muestra aleatoria de 10k filas. \n",
    "\n",
    "Luego verificar estructura.\n",
    "\n",
    "Y finalmente crear 2 vectores, uno para parametros (X), y otro para etiquetas (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b42a1e0-9e89-464e-8d40-7a6868ac7586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 55)\n",
      "Cover_Type\n",
      "2    4841\n",
      "1    3683\n",
      "3     623\n",
      "7     347\n",
      "6     299\n",
      "5     160\n",
      "4      47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = fetch_covtype(as_frame=True)\n",
    "df = data.frame\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "print(df.shape)\n",
    "print(df['Cover_Type'].value_counts())\n",
    "\n",
    "X = df.drop(columns=['Cover_Type'])\n",
    "y = df['Cover_Type']\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6ead1-9e77-4246-99a9-6af14e9709d9",
   "metadata": {},
   "source": [
    "K-Means.\n",
    "\n",
    "Usando una proporcion 80-20 con 4 configuraciones diferentes.\n",
    "\n",
    "Cada metodo tiene una evaluacion como silhouette score, esto para comparalos al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bf4916-240e-4e14-93d8-60f59d81ba27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-MEANS\n",
      "Config 1: {'n_clusters': 3, 'init': 'random', 'n_init': 10, 'max_iter': 300}, Silhouette Score = 0.1021\n",
      "Config 2: {'n_clusters': 5, 'init': 'random', 'n_init': 15, 'max_iter': 300}, Silhouette Score = 0.0807\n",
      "Config 3: {'n_clusters': 7, 'init': 'random', 'n_init': 20, 'max_iter': 500}, Silhouette Score = 0.1387\n",
      "Config 4: {'n_clusters': 9, 'init': 'random', 'n_init': 25, 'max_iter': 400}, Silhouette Score = 0.1700\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"K-MEANS\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "kmeans_configs = [\n",
    "    {\"n_clusters\": 3, \"init\": \"random\", \"n_init\": 10, \"max_iter\": 300},\n",
    "    {\"n_clusters\": 5, \"init\": \"random\", \"n_init\": 15, \"max_iter\": 300},\n",
    "    {\"n_clusters\": 7, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500},\n",
    "    {\"n_clusters\": 9, \"init\": \"random\", \"n_init\": 25, \"max_iter\": 400},\n",
    "]\n",
    "\n",
    "for i, cfg in enumerate(kmeans_configs, 1):\n",
    "    model = KMeans(**cfg, random_state=42)\n",
    "    model.fit(X_train)\n",
    "    labels = model.labels_\n",
    "\n",
    "    sil_score = silhouette_score(X_train, labels)\n",
    "    results.append({\n",
    "        \"model_type\": \"KMeans\",\n",
    "        \"config\": cfg,\n",
    "        \"silhouette\": sil_score\n",
    "    })\n",
    "    print(f\"Config {i}: {cfg}, Silhouette Score = {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec414ff-859c-4e8f-980d-6f3568c4feed",
   "metadata": {},
   "source": [
    "K-Means++. (init:k-means++)\n",
    "\n",
    "Usando una proporcion 80-20 con 4 configuraciones diferentes.\n",
    "\n",
    "Cada metodo tiene una evaluacion como silhouette score, esto para comparalos al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560ed6c9-49eb-41ea-b3bf-78e6a35f1a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-MEANS++\n",
      "Config 1: {'n_clusters': 3, 'init': 'k-means++', 'n_init': 10, 'max_iter': 300}, Silhouette Score = 0.1021\n",
      "Config 2: {'n_clusters': 5, 'init': 'k-means++', 'n_init': 20, 'max_iter': 300}, Silhouette Score = 0.1154\n",
      "Config 3: {'n_clusters': 7, 'init': 'k-means++', 'n_init': 15, 'max_iter': 500}, Silhouette Score = 0.0970\n",
      "Config 4: {'n_clusters': 9, 'init': 'k-means++', 'n_init': 25, 'max_iter': 400}, Silhouette Score = 0.1159\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"K-MEANS++\")\n",
    "\n",
    "kmeanspp_configs = [\n",
    "    {\"n_clusters\": 3, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 300},\n",
    "    {\"n_clusters\": 5, \"init\": \"k-means++\", \"n_init\": 20, \"max_iter\": 300},\n",
    "    {\"n_clusters\": 7, \"init\": \"k-means++\", \"n_init\": 15, \"max_iter\": 500},\n",
    "    {\"n_clusters\": 9, \"init\": \"k-means++\", \"n_init\": 25, \"max_iter\": 400},\n",
    "]\n",
    "\n",
    "for i, cfg in enumerate(kmeanspp_configs, 1):\n",
    "    model = KMeans(**cfg, random_state=42)\n",
    "    model.fit(X_train)\n",
    "    labels = model.labels_\n",
    "    sil_score = silhouette_score(X_train, labels)\n",
    "    results.append({\n",
    "        \"model_type\": \"KMeans++\",\n",
    "        \"config\": cfg,\n",
    "        \"silhouette\": sil_score\n",
    "    })\n",
    "    print(f\"Config {i}: {cfg}, Silhouette Score = {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8a634-3b4e-474a-9ce4-9e29fe7ce1ed",
   "metadata": {},
   "source": [
    "MeanShift\n",
    "\n",
    "Usando una proporcion 80-20 con 4 configuraciones diferentes.\n",
    "\n",
    "Cada metodo tiene una evaluacion como silhouette score, esto para comparalos al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdfc1b5-996c-4a5e-a27a-a5aaeb372e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MeanShift\n",
      "Bandwidth estimado base: 7.5653\n",
      "Config 1: {'bandwidth': np.float64(3.782648713514269)}, Silhouette Score = 0.3996, Clusters encontrados = 84\n",
      "Config 2: {'bandwidth': np.float64(7.565297427028538)}, Silhouette Score = 0.3058, Clusters encontrados = 26\n",
      "Config 3: {'bandwidth': np.float64(11.347946140542806)}, Silhouette Score = 0.4296, Clusters encontrados = 21\n",
      "Config 4: {'bandwidth': np.float64(15.130594854057076)}, Silhouette Score = 0.5170, Clusters encontrados = 16\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"MeanShift\")\n",
    "\n",
    "bandwidth_estimate = estimate_bandwidth(X_train, quantile=0.2, n_samples=500)\n",
    "print(f\"Bandwidth estimado base: {bandwidth_estimate:.4f}\")\n",
    "\n",
    "meanshift_configs = [\n",
    "    {\"bandwidth\": bandwidth_estimate * 0.5},\n",
    "    {\"bandwidth\": bandwidth_estimate},\n",
    "    {\"bandwidth\": bandwidth_estimate * 1.5},\n",
    "    {\"bandwidth\": bandwidth_estimate * 2.0},\n",
    "]\n",
    "\n",
    "for i, cfg in enumerate(meanshift_configs, 1):\n",
    "    model = MeanShift(**cfg)\n",
    "    model.fit(X_train)\n",
    "    labels = model.labels_\n",
    "\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        sil_score = silhouette_score(X_train, labels)\n",
    "    else:\n",
    "        sil_score = -1\n",
    "\n",
    "    results.append({\n",
    "        \"model_type\": \"MeanShift\",\n",
    "        \"config\": cfg,\n",
    "        \"silhouette\": sil_score\n",
    "    })\n",
    "    print(f\"Config {i}: {cfg}, Silhouette Score = {sil_score:.4f}, Clusters encontrados = {len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daab263-ed12-45bd-b28e-7c8082cb3c07",
   "metadata": {},
   "source": [
    "JUSTIFICACION DE PARAMETROS:\n",
    "\n",
    "En K-Means y K-Means++, se ajustaron los parametros \"n_clusters\", \"n_init\" y \"max_iter\".\n",
    "\n",
    "Donde n_clusters es el numero de clusters con los que se realiza el modelo, se utilizaron valores como 3 5 7 9, intentando probar con cantidades no muy grandes, ya que si se utilizan 20, 100 o 1000, se puede llegar a un punto de demasiada segmentacion, los cuales comparten la misma informacion, y solo no se unieron por distancia.\n",
    "\n",
    "n_init es el numero de inicializaciones independientes para reducir el riesgo de estancarse en minimos locales, estos valores van de 10 a 25, y fue incrementado junto con el numero de clusters.\n",
    "\n",
    "Finalmente max_iter es el numero de iteraciones por cada iteracion, aumentar este valor permite una convergencia mas precisa, aunque en un modelo bien configurado y con un dataset bien balanceado, esta convergencia nunca deberia tomar mas de 300 iteraciones. \n",
    "\n",
    "En MeanShift, se calcula el modelo utilizando el parametro \"bandwith\" que es la distancia en la que se conectan los diferentes puntos, por ende, se crea un aproximado base usando la formula \"estimate_bandwidth\", y se intenta con multiplos de ese valor (0.5; 1; 1.5; 2), no se intenta con valores muy grandes o pequeños debido a que el sistema convergeria a todos los puntos en un unico grupo, o a que se creen montones de pequeños grupos con la misma informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43a614-4edb-49c7-9596-de9dc0ff4b57",
   "metadata": {},
   "source": [
    "Evaluación global de las 12 configuraciones:\n",
    "\n",
    "Se toman los 12 modelos entrenados anteriormente, y se ordenan en base a su puntaje de silhuette, obteniendo el top 3.\n",
    "\n",
    "Luego, se compara la informacion de etiqueta, con la etiqueta real usando el resto (20%) del dataset base, entregando una tasa de aciertos final por cada modelo en el top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69633f5-ef33-476f-8c89-0afd63586c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 configuraciones globales por Silhouette Score\n",
      "{'model_type': 'MeanShift', 'config': {'bandwidth': np.float64(15.130594854057076)}, 'silhouette': 0.5170171193037753}\n",
      "{'model_type': 'MeanShift', 'config': {'bandwidth': np.float64(11.347946140542806)}, 'silhouette': 0.4296315428885252}\n",
      "{'model_type': 'MeanShift', 'config': {'bandwidth': np.float64(3.782648713514269)}, 'silhouette': 0.3996245643432745}\n",
      "\n",
      "Modelo 1: MeanShift, Config: {'bandwidth': np.float64(15.130594854057076)}\n",
      "\n",
      "Coincidencia entre etiquetas reales y dominantes = 0.4920\n",
      "\n",
      "Modelo 2: MeanShift, Config: {'bandwidth': np.float64(11.347946140542806)}\n",
      "\n",
      "Coincidencia entre etiquetas reales y dominantes = 0.4960\n",
      "\n",
      "Modelo 3: MeanShift, Config: {'bandwidth': np.float64(3.782648713514269)}\n",
      "\n",
      "Coincidencia entre etiquetas reales y dominantes = 0.6350\n"
     ]
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x[\"silhouette\"], reverse=True)\n",
    "top3 = results[:3]\n",
    "\n",
    "print()\n",
    "print(\"Top 3 configuraciones globales por Silhouette Score\")\n",
    "for res in top3:\n",
    "    print(res)\n",
    "\n",
    "for i, res in enumerate(top3, 1):\n",
    "    algo = res[\"model_type\"]\n",
    "    cfg = res[\"config\"]\n",
    "    print(f\"\\nModelo {i}: {algo}, Config: {cfg}\")\n",
    "\n",
    "    if algo in [\"KMeans\", \"KMeans++\"]:\n",
    "        model = KMeans(**cfg, random_state=42)\n",
    "    else:\n",
    "        model = MeanShift(**cfg)\n",
    "\n",
    "    model.fit(X_train)\n",
    "    test_clusters = model.predict(X_test)\n",
    "\n",
    "    train_clusters = model.labels_\n",
    "    cluster_labels = {}\n",
    "    for cluster_id in np.unique(train_clusters):\n",
    "        mask = train_clusters == cluster_id\n",
    "        dominant_label = y_train.iloc[mask].mode()[0]\n",
    "        cluster_labels[cluster_id] = dominant_label\n",
    "\n",
    "    y_pred = [cluster_labels[c] for c in test_clusters if c in cluster_labels]\n",
    "    valid_idx = [i for i, c in enumerate(test_clusters) if c in cluster_labels]\n",
    "    match_ratio = np.mean(np.array(y_pred) == y_test.values[valid_idx])\n",
    "    print()\n",
    "    print(f\"Coincidencia entre etiquetas reales y dominantes = {match_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368d0b8-3723-4a3b-bf94-6efc2a30bd49",
   "metadata": {},
   "source": [
    "Finalmente, se observan los siguientes resultados:\n",
    "\n",
    "TOP1: Meanshift con 2*bandwith, obtuvo un 51.7% de silhouette score y una coincidencia de 49.20% con las etiquetas reales.\n",
    "\n",
    "TOP2: Meanshift con 1.5*bandwith, alcanzó un silhouette score de 0.43 y una coincidencia de 49.60%, resultado equivalente al del top 1.\n",
    "\n",
    "TOP3: Meanshift con 0.5*bandwitch, logró un silhouette score de 0.39 y una coincidencia de 63.50%, siendo el mejor entre los tres.\n",
    "\n",
    "Estos datos, demuestran como el modelo esta funcionando correctamente, siendo capaz de predecir hasta cierto punto el resultado, llegando hasta casi un 50/50 en el TOP1 y TOP2, y con un 64% en el mejor caso.\n",
    "\n",
    "Teniendo en cuenta que la etiqueta tiene 7 clases, estos modelos permiten pasar de un 14% de exito (seleccion aleatoria) a un 49% o 64%, segun el modelo utilizado.\n",
    "\n",
    "Ahora, respondiendo la pregunta ¿Este procedimiento resulta razonable para asignar etiquetas faltantes?\n",
    "\n",
    "La respuesta es un depende, ya que en el mejor de los casos, se obtuvo solo un rendimiento del 64%, lo que no se puede considerar demasiado confliable, por ende, se deberia buscar un metodo algo mas exacto (rondando el 85+% de aciertos) para que sea razonable de aplicar, en caso de no tener disponible otro metodo, si es razonable el utilizarlo, ya que al ser un 64%, el modelo permite predecir la mayoria de situaciones, en vez de un modelo puramente aleatorio con un 14%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e93ff-30fa-4a64-ad18-d599a161985b",
   "metadata": {},
   "source": [
    "PUNTO 2:\n",
    "\n",
    "Utilizando el mismo conjunto de datos previamente seleccionado, diseñe e implemente una técnica que permita entrenar en paralelo múltiples instancias (al menos tres por técnica) de Regresión Logística y SVM, variando sus hiperparámetros (por ejemplo: batch size, tasa de aprendizaje, etc, según sea el caso). \n",
    "\n",
    "Los parámetros de cada configuración deberán definirse en un archivo de configuración externo, y el entrenamiento deberá realizarse utilizando el 80% de los datos. \n",
    "\n",
    "Cada modelo se evaluará periódicamente (solo con datos de entrenamiento), y por cada cinco épocas deberá descartarse la configuración con peor desempeño entre todas las configuraciones restantes. Para las dos mejores configuraciones, presente métricas de evaluación utilizando el conjunto de testing, es decir, el 20% de los datos. \n",
    "\n",
    "Analice los resultados obtenidos en función de los hiperparámetros seleccionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2664901-a210-45fe-be62-124abfab4240",
   "metadata": {},
   "source": [
    "Cargar configuracion desde archivo externo (configs.json) tiene que estar en el mismo directorio que el .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab5131c-4de7-4743-9fa8-80a4224fbdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraciones cargadas: 6 modelos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)[\"models\"]\n",
    "\n",
    "print(f\"Configuraciones cargadas: {len(configs)} modelos\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05851c0f-af03-4c9d-8c18-f0510dcff5a3",
   "metadata": {},
   "source": [
    "Subdividir parte del train para evaluacion periodica, y creacion de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c66a06-1ff0-4413-a1f6-48af48880f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_main, X_train_eval, y_train_main, y_train_eval = tts(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "\n",
    "models_meta = []\n",
    "for cfg in configs:\n",
    "    loss = \"log_loss\" if cfg[\"type\"] == \"logistic\" else \"hinge\"\n",
    "    clf = SGDClassifier(\n",
    "        loss=loss,\n",
    "        penalty=\"l2\",\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        eta0=cfg[\"eta0\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    models_meta.append({\n",
    "        \"name\": cfg[\"name\"],\n",
    "        \"type\": cfg[\"type\"],\n",
    "        \"cfg\": cfg,\n",
    "        \"clf\": clf,\n",
    "        \"epochs_done\": 0,\n",
    "        \"max_epochs\": cfg[\"max_epochs\"],\n",
    "        \"batch_size\": cfg[\"batch_size\"],\n",
    "        \"alive\": True,\n",
    "        \"last_eval_acc\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff6178-d779-4be7-beb4-d74d016aef92",
   "metadata": {},
   "source": [
    "Inicializar pesos, y definir la funcion de entrenamiento por bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c87d4680-7bb8-47eb-9434-23f88f8d3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models_meta:\n",
    "    init_batch = min(100, X_train_main.shape[0])\n",
    "    m[\"clf\"].partial_fit(X_train_main[:init_batch], y_train_main[:init_batch], classes=classes)\n",
    "\n",
    "\n",
    "def train_chunk(model, X_main, y_main, epochs_chunk, batch_size, classes):\n",
    "    n = X_main.shape[0]\n",
    "    for ep in range(epochs_chunk):\n",
    "        X_sh, y_sh = skshuffle(X_main, y_main, random_state=int(time.time() * 1000) % 2**32)\n",
    "        for start in range(0, n, batch_size):\n",
    "            end = min(start + batch_size, n)\n",
    "            Xb, yb = X_sh[start:end], y_sh[start:end]\n",
    "            model.partial_fit(Xb, yb, classes=classes)\n",
    "    y_pred_eval = model.predict(X_train_eval)\n",
    "    acc = accuracy_score(y_train_eval, y_pred_eval)\n",
    "    return model, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824fef4-10c1-4509-8f79-dd81111d76c2",
   "metadata": {},
   "source": [
    "Entrenamiento iterativo en paralelo con eliminacion del peor cada 5 epocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef38751-ef6c-4792-bc51-f99a30180691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento paralelo (6 configuraciones, 5 épocas por ronda)\n",
      "\n",
      "--- Ronda 1 | modelos activos: 6 ---\n",
      "log_B (logistic) -> acc_train_eval=0.7050\n",
      "svm_A (svm) -> acc_train_eval=0.6987\n",
      "log_A (logistic) -> acc_train_eval=0.7075\n",
      "svm_B (svm) -> acc_train_eval=0.6963\n",
      "log_C (logistic) -> acc_train_eval=0.6900\n",
      "svm_C (svm) -> acc_train_eval=0.6837\n",
      "Eliminado: svm_C (0.6837)\n",
      "\n",
      "--- Ronda 2 | modelos activos: 5 ---\n",
      "log_B (logistic) -> acc_train_eval=0.7000\n",
      "svm_A (svm) -> acc_train_eval=0.6975\n",
      "log_A (logistic) -> acc_train_eval=0.7087\n",
      "svm_B (svm) -> acc_train_eval=0.7163\n",
      "log_C (logistic) -> acc_train_eval=0.6913\n",
      "Eliminado: log_C (0.6913)\n",
      "\n",
      "--- Ronda 3 | modelos activos: 4 ---\n",
      "log_B (logistic) -> acc_train_eval=0.7063\n",
      "svm_B (svm) -> acc_train_eval=0.7087\n",
      "log_A (logistic) -> acc_train_eval=0.7087\n",
      "svm_A (svm) -> acc_train_eval=0.7137\n",
      "Eliminado: log_B (0.7063)\n",
      "\n",
      "--- Ronda 4 | modelos activos: 3 ---\n",
      "log_A (logistic) -> acc_train_eval=0.6975\n",
      "svm_A (svm) -> acc_train_eval=0.7087\n",
      "svm_B (svm) -> acc_train_eval=0.7025\n",
      "Eliminado: log_A (0.6975)\n",
      "\n",
      "Menos de 3 modelos activos, deteniendo eliminaciones.\n",
      "\n",
      "Finalistas:\n",
      "- svm_A (svm) acc_train_eval=0.7087\n",
      "- svm_B (svm) acc_train_eval=0.7025\n"
     ]
    }
   ],
   "source": [
    "epochs_chunk = 5\n",
    "max_rounds = max(m[\"max_epochs\"] for m in models_meta) // epochs_chunk + 1\n",
    "print(f\"Iniciando entrenamiento paralelo ({len(models_meta)} configuraciones, {epochs_chunk} épocas por ronda)\\n\")\n",
    "\n",
    "for round_i in range(max_rounds):\n",
    "    alive = [m for m in models_meta if m[\"alive\"] and m[\"epochs_done\"] < m[\"max_epochs\"]]\n",
    "    if len(alive) <= 2:\n",
    "        print(\"Menos de 3 modelos activos, deteniendo eliminaciones.\")\n",
    "        break\n",
    "\n",
    "    print(f\"--- Ronda {round_i+1} | modelos activos: {len(alive)} ---\")\n",
    "    futures = {}\n",
    "    with ThreadPoolExecutor(max_workers=min(len(alive), 4)) as exe:\n",
    "        for m in alive:\n",
    "            futures[exe.submit(train_chunk, m[\"clf\"], X_train_main, y_train_main, epochs_chunk, m[\"batch_size\"], classes)] = m\n",
    "        for fut in as_completed(futures):\n",
    "            m = futures[fut]\n",
    "            clf_updated, acc = fut.result()\n",
    "            m[\"clf\"] = clf_updated\n",
    "            m[\"epochs_done\"] += epochs_chunk\n",
    "            m[\"last_eval_acc\"] = acc\n",
    "            print(f\"{m['name']} ({m['type']}) -> acc_train_eval={acc:.4f}\")\n",
    "\n",
    "    # Eliminar el peor\n",
    "    alive = [m for m in models_meta if m[\"alive\"]]\n",
    "    if len(alive) <= 2:\n",
    "        break\n",
    "    worst = min(alive, key=lambda x: x[\"last_eval_acc\"] or -1.0)\n",
    "    worst[\"alive\"] = False\n",
    "    print(f\"Eliminado: {worst['name']} ({worst['last_eval_acc']:.4f})\\n\")\n",
    "\n",
    "# Seleccionar ganadores\n",
    "finalists = sorted([m for m in models_meta if m[\"alive\"]], key=lambda x: x[\"last_eval_acc\"] or 0.0, reverse=True)[:2]\n",
    "print(\"\\nFinalistas:\")\n",
    "for f in finalists:\n",
    "    print(f\"- {f['name']} ({f['type']}) acc_train_eval={f['last_eval_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261bf32-5756-4126-ac22-132ac49c8436",
   "metadata": {},
   "source": [
    "Evaluar finalistas, utilizando los datos restantes (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f1ed88-1660-4d33-828c-1b487d7996da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== svm_A (svm) ==\n",
      "Accuracy test: 0.7040\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7246    0.6282    0.6730       737\n",
      "           2     0.7126    0.8326    0.7680       968\n",
      "           3     0.6203    0.7840    0.6926       125\n",
      "           4     0.0000    0.0000    0.0000         9\n",
      "           5     0.0000    0.0000    0.0000        32\n",
      "           6     0.2222    0.0667    0.1026        60\n",
      "           7     0.7400    0.5362    0.6218        69\n",
      "\n",
      "    accuracy                         0.7040      2000\n",
      "   macro avg     0.4314    0.4068    0.4083      2000\n",
      "weighted avg     0.6829    0.7040    0.6875      2000\n",
      "\n",
      "\n",
      "== svm_B (svm) ==\n",
      "Accuracy test: 0.7145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7064    0.6988    0.7026       737\n",
      "           2     0.7400    0.8058    0.7715       968\n",
      "           3     0.6102    0.8640    0.7152       125\n",
      "           4     0.0000    0.0000    0.0000         9\n",
      "           5     0.0000    0.0000    0.0000        32\n",
      "           6     0.0000    0.0000    0.0000        60\n",
      "           7     0.6842    0.3768    0.4860        69\n",
      "\n",
      "    accuracy                         0.7145      2000\n",
      "   macro avg     0.3916    0.3922    0.3822      2000\n",
      "weighted avg     0.6802    0.7145    0.6938      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'svm_A',\n",
       "  'type': 'svm',\n",
       "  'train_eval_acc': 0.70875,\n",
       "  'test_acc': 0.704},\n",
       " {'name': 'svm_B',\n",
       "  'type': 'svm',\n",
       "  'train_eval_acc': 0.7025,\n",
       "  'test_acc': 0.7145}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary = []\n",
    "for f in finalists:\n",
    "    clf = f[\"clf\"]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n== {f['name']} ({f['type']}) ==\")\n",
    "    print(f\"Accuracy test: {acc_test:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
    "    results_summary.append({\n",
    "        \"name\": f[\"name\"],\n",
    "        \"type\": f[\"type\"],\n",
    "        \"train_eval_acc\": f[\"last_eval_acc\"],\n",
    "        \"test_acc\": acc_test\n",
    "    })\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e4fcf-3cf3-4eca-96db-489341a8bf8f",
   "metadata": {},
   "source": [
    "Analisis de resultados:\n",
    "\n",
    "Los 2 mejores modelos de regresion fueron: smv_A y svm_B, ambos llegaron a un desempeño final muy similar de 70.4% y 71.4% de aciertos sobre el conjunto de prueba.\n",
    "\n",
    "El modelo SVM_A logro un rendimiento ligeramente superior, especialmente la clase 2, que es a mas representada en el conjunto de datos. Ambos modelos lograron identificar correctamente las clases mas frecuentes (1, 2, 3), pero fallaron con las clases menos presentes (4, 5, 6), donde la cantidad de ejemplos disponibles fue demasiado baja para que se pudiera identificar algun patron predictivo, las 3 menores clases juntas, conforman alrededor de un 5% de los datos totales, lo que muestra un claro desbalance en el dataset utilizado.\n",
    "\n",
    "El modelo SVM_B, aunque con una accuracy ligeramente menor, mostro un puntaje f1 superior, lo que sugiere una convergencia mas estable durante el entrenamiento.\n",
    "\n",
    "En resumen, los resultados fueron coherentes con respecto a los datos utilizados y los parametros seleccionados, donde este fue incapaz de converger a una solucion para todas las clases de la etiqueta, debido a el desbalance del dataset utilizado, lo que muestra la importancia de aplicar tecnicas de balanceo de datos o ponderacion por clase en casos futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6b846-84a4-415c-b95e-ed93572b5778",
   "metadata": {},
   "source": [
    "Finalmente, es necesario el mencionar que para esta tarea se utilizo Inteligencia Artificial, especificamente ChatGPT para la creacion del codigo inicial, luego (debido a la incompetencia de este para todo proyecto mayor a 100~ lineas de codigo) fue necesario el debugear y resolver el resto de problemas relacionados al codigo manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e4081-8ca3-4a72-aec5-381189b37b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
